{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## The perceptron\n",
    "\n",
    "\n",
    "    Hand-in bug-free (try \"Kernel\" > \"Restart & Run All\") and including all (textual as well as figural) output via Blackboard before the deadline (see Blackboard).\n",
    "    \n",
    "Learning goals:\n",
    "1. Implement a perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: The activation function (1 point)\n",
    "The perceptron uses the *linear threshold activation* function $g(\\mathbf{x})$ with $\\theta=0$. Write a function ```linear_threshold(x, theta)``` that computes this activation given any input $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The activation function\n",
    "def linear_threshold(x, theta):\n",
    "    if x >= theta:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Perceptron output (1 point)\n",
    "The output $y$ of a perceptron is given by $y=g(\\mathbf{w}^\\top \\mathbf{x})$, with input vector $\\mathbf{x}$, the weight vector $\\mathbf{w}$, and the activation function $g$. Write a function ```compute_output(x,w)``` that computes the output of a perceptron, given a single pattern $\\mathbf{x}$ and the current perceptron weights $\\mathbf{w}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of a perceptron\n",
    "def compute_output(x,w):\n",
    "    result = np.dot(w.T,x)\n",
    "    return linear_threshold(result, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Weight update (1 point)\n",
    "A perceptron is trained (i.e. it learns the right weights) following the perceptron convergence procedure. Write a function ```update_weights(w, x, y, t)``` that performs this procedure. Specifically, write a function that returns the updated perceptron weights following the rule from the lecture, given one input pattern $\\mathbf{x}$, its target output $\\mathbf{t}$, the current set of weights $\\mathbf{w}$ and the (already calculated) output of the perceptron $\\mathbf{y}$. \n",
    "\n",
    "You don't need to calculate the perceptron output $\\mathbf{y}$ here, it will be calculated in the final perceptron training function with your ```compute_output()``` function. \n",
    "\n",
    "Hint: This is a very short function again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -2. -3.]\n"
     ]
    }
   ],
   "source": [
    "# Perceptron weight update\n",
    "def update_weights(w,x,y,t):\n",
    "    return (w + (t - y)*x)\n",
    "w = np.zeros(3)\n",
    "x = np.array([1,2,3])\n",
    "t = 0\n",
    "y = 1\n",
    "print(update_weights(w,x,y,t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: Training (1.5 points)\n",
    "You now have implemented all the building blocks for a perceptron. Now, write a function ```perceptron_train(X, T, num_epochs)``` that trains and returns weights $\\mathbf{w}$ for a perceptron, given a dataset $\\mathbf{X}$ and targets $\\mathbf{T}$.\n",
    "\n",
    "`n` is the number of training examples. `m` is the number of weights. Expect $\\mathbf{X}$ to be a matrix containing the training examples with dimensions `(m,n)` and $\\mathbf{T}$ containing the targets for each example, a vector with length `n`.\n",
    "\n",
    "It should train for 10 epochs (iterations over all training examples). Make use of `np.random.permutation` to avoid that you are always iterating over the examples in the same order. \n",
    "\n",
    "For now only implement ```perceptron_train(X, T, num_epochs)```. We will call and test it later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.  2.]\n",
      "[ 0.  0.  0.]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-11d95e7730f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mperceptron_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-11d95e7730f1>\u001b[0m in \u001b[0;36mperceptron_train\u001b[1;34m(X, T, num_epochs)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[1;31m# Compute the output of the perceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[1;31m# Update the weights of the perceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-76933f33213d>\u001b[0m in \u001b[0;36mcompute_output\u001b[1;34m(x, w)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Output of a perceptron\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mlinear_threshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "def perceptron_train(X, T, num_epochs=10):\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initialize the right number of weights as zeros\n",
    "    w = np.zeros(m)\n",
    "    # Loop over epochs\n",
    "    for i in range(0,num_epochs):\n",
    "\n",
    "        # Loop over all examples in random order\n",
    "        for j in np.random.permutation(n):\n",
    "            # Take an example\n",
    "            x = X[j]\n",
    "            print(x)\n",
    "            print(w)\n",
    "            t = T[j]\n",
    "\n",
    "            # Compute the output of the perceptron\n",
    "            y = compute_output(x,w)\n",
    "            # Update the weights of the perceptron\n",
    "            w = update_weights(w,x,y,t)\n",
    "    return w\n",
    "X = np.array([[4.0,2.0],[1,1], [0,0]])\n",
    "T = np.array([1,0])\n",
    "perceptron_train(X,T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: Testing (1.5 points)\n",
    "In addition to the training function, write a function `perceptron_test(X,w)` that computes and returns the outputs $\\mathbf{Y}$ for a given dataset $\\mathbf{X}$ and a perceptron given by its weights $\\mathbf{w}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perceptron_test(X, w):\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Create an output array Y that you use to store the perceptron outputs\n",
    "    \n",
    "    # Loop over the examples\n",
    "    \n",
    "        # Take an example\n",
    "\n",
    "        # Compute the output of the perceptron\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6: OR (1 point)\n",
    "Use your functions to train and test a perceptron on the OR problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs $\\mathbf{T}$ for the OR problem  to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 1, 1, 1], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"OR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7: AND (1 point)\n",
    "Train and test your perceptron on the AND problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs for the AND problem $\\mathbf{T}$ to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 0, 0, 1], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"AND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8: XOR (1 point)\n",
    "Train and test your perceptron on the XOR problem, given by input patterns $\\mathbf{X}$ and targets $\\mathbf{T}$. \n",
    "\n",
    "Print your trained perceptron's outputs $\\mathbf{Y}$ and the expected outputs for the XOR problem $\\mathbf{T}$ to check whether your perceptron has learned successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]], dtype=\"float32\").T\n",
    "\n",
    "# Targets\n",
    "T = np.array([0, 1, 1, 0], dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plt.figure()\n",
    "for i_example in range(X.shape[1]):\n",
    "    if T[i_example] == 1:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"or\")\n",
    "    else:\n",
    "        plt.plot(X[0, i_example], X[1, i_example], \"ob\")\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.title(\"XOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add bias terms\n",
    "X = np.vstack((np.ones((1, X.shape[1])), X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the perceptron\n",
    "\n",
    "# Apply the perceptron\n",
    "\n",
    "# Print predictions and targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9: Interpretation (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Which of the three problems OR, AND and XOR did the perceptron learn, and which did it not learn?\n",
    "1. Which property do the patterns in $\\mathbf{X}$ need to have so that the perceptron can learn them? \n",
    "1. Which of the three problems do or do not have this property?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write your answer here.\n",
    "1. Write your answer here.\n",
    "1. Write your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
